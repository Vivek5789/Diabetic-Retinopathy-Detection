{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APTOS 2019 Blindness Detection\n",
    "---\n",
    "In this Kernel, we will design a Machine learning model,which will help in identifing the eyes disease.  As this is a imaged based problem, we will use Deep Learning for model design.\n",
    "\n",
    "Diabetic retinopathy affects blood vessels in the light-sensitive tissue called the retina that lines the back of the eye. It is the most common cause of vision loss among people with diabetes and the leading cause of vision impairment and blindness among working-age adults. It don't have any earaly symtoms. As of now, Retena photography is a way to detect the stage of Blindness. Automating it with ml, will help a lot in health domain. \n",
    "\n",
    "---------------------------------------\n",
    "1. [Import Required Libraries](#1)\n",
    "1. [Loading Data ](#2)\n",
    "1. [Data Visualization](#3)\n",
    "1. [Train and Test dataset](#4)\n",
    "1. [Data Pre-Processing](#6)\n",
    "1. [Image Data Generator](#7)\n",
    "1. [Model Architecture Design](#8)\n",
    "1. [Keras Callback Funcations](#9)\n",
    "1. [Transfer Learning](#10)\n",
    "1. [Validation Accuracy & Loss](#11)\n",
    "1. [Validation Accuracy](#12)\n",
    "1. [Test-Time Augmentation](#13)\n",
    "1. [Visualization Test Result](#14)\n",
    "------------------------------------\n",
    "- Design CNN from Scratch\n",
    "- Use pre-train model for Blindness Detection\n",
    " \n",
    " Stages Of Diabetic Retinopathy\n",
    "- NO DR\n",
    "- Mild\n",
    "- Moderate \n",
    "- Servere\n",
    "- Proliferative DR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import gc\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import set_random_seed\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "import math\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.activations import elu\n",
    "from keras.activations import relu\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tqdm import tqdm\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "print(os.listdir(\"../input/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "#### Exploratory Data Analysis\n",
    "- Loading Data \n",
    "- Data Disribution\n",
    "- Data Visualization\n",
    "\n",
    "Setup all the param, which we will use in model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7\n",
    "np.random.seed(SEED)\n",
    "set_random_seed(SEED)\n",
    "dir_path = \"../input/aptos2019-blindness-detection/\"\n",
    "IMG_DIM = 224  # 224 399 #\n",
    "BATCH_SIZE = 12\n",
    "CHANNEL_SIZE = 3\n",
    "NUM_EPOCHS = 60\n",
    "size=224\n",
    "TRAIN_DIR = 'train_images'\n",
    "TEST_DIR = 'test_images'\n",
    "FREEZE_LAYERS = 2  # freeze the first this many layers for training\n",
    "CLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(dir_path, \"train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(dir_path, \"test.csv\"))\n",
    "NUM_CLASSES = df_train['diagnosis'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set has {} samples and {} classes.\".format(df_train.shape[0], df_train.shape[1]))\n",
    "print(\"Testing set has {} samples and {} classes.\".format(df_test.shape[0], df_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image(image):\n",
    "    img = cv2.blur(image,(2,2))\n",
    "    slice1Copy = np.uint8(img)\n",
    "    canny = cv2.Canny(slice1Copy, 0, 50)\n",
    "    pts = np.argwhere(canny>0)\n",
    "    y1,x1 = pts.min(axis=0)\n",
    "    y2,x2 = pts.max(axis=0)\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "    cropped_img = cv2.resize(cropped_img, size)\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img=cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(cv2.imread(path), size)\n",
    "    img = get_cropped_image(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "#### Split DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = df_train[\"diagnosis\"].values.tolist()\n",
    "#labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trai, x_val, y_train, y_val = train_test_split(df_train.id_code,df_train[\"diagnosis\"], test_size=0.15,\n",
    "                                                    random_state=SEED,stratify=df_train[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train).values\n",
    "y_valid = pd.get_dummies(y_val).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "# Image Data Generator\n",
    "In this section willl use Keras ImageDataGenerator class for generating data for Keras model. It is used for data generation, increasing the data size. with the help of ImageDataGenerator we will do image \"augment\" via a number of random transformations, so that our model would never see twice the exact same picture. \n",
    "\n",
    "Training Deep Learning model can perform better with more data, and augementation technique can create variations of data that can increase the ababiliy of fit model to gene\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the imageDatagenerator Instance \n",
    "datagenerator=ImageDataGenerator(#rescale=1./255,\n",
    "#                                       validation_split=0.15, \n",
    "                                         horizontal_flip=True,\n",
    "                                         vertical_flip=True, \n",
    "                                         rotation_range=40, \n",
    "                                         zoom_range=0.2, \n",
    "                                         shear_range=0.1,\n",
    "                                        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\"\n",
    "# Loading image\n",
    "img = load_img(imgPath)\n",
    "data = img_to_array(img)\n",
    "samples =np.expand_dims(data, 0)\n",
    "i=5\n",
    "it=datagenerator.flow(samples , batch_size=1)\n",
    "for i in range(5):\n",
    "    plt.subplot(230 + 1 + i)\n",
    "    batch = it.next()\n",
    "    image = batch[0].astype('uint8')\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "train_dir = \"../input/aptos2019-blindness-detection/train_images/\"\n",
    "training_paths = [train_dir + str(x) + str(\".png\") for x in df_train[\"id_code\"]]\n",
    "images = np.empty((len(df_train), 256,256,3), dtype = np.uint8)\n",
    "for i, path in tqdm_notebook(enumerate(training_paths)):\n",
    "    images[i,:,:,:] = load_img(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                         vertical_flip=True, \n",
    "                                         rotation_range=60, \n",
    "                                         zoom_range=0.2, \n",
    "                                         shear_range=0.1,\n",
    "                                        fill_mode='nearest')\n",
    "# valid_datagen=image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINCE ABOVE PREPROCESS CODE ISNT WORKING WE WORK WITH PREPROCESSED IMGS FROM XCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"../input/preprocessed-aptos-images/x_train_224_2019.npy\", mmap_mode=None, allow_pickle=False, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid=np.load(\"../input/preprocessed-aptos-images/x_valid_224_2019.npy\", mmap_mode=None, allow_pickle=False, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train,y_train,batch_size=12)\n",
    "valid_generator = train_datagen.flow(x_valid,y_valid,batch_size=12\n",
    "                                                    )\n",
    "#del x_train\n",
    "# # del x_test\n",
    "#del y_train\n",
    "# del y_test\n",
    "gc.collect()\n",
    "#  color_mode= \"grayscale\",\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "# Keras Callback Funcations\n",
    "- Call Back functions Eraly Stoping and Learning Rate Reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eraly_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n",
    "# Reducing the Learning Rate if result is not improving. \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUB_TRAIN_STEPS = train_generator.n // train_generator.batch_size\n",
    "NUB_VALID_STEPS = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "NUB_TRAIN_STEPS, NUB_VALID_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a>\n",
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "def create_resnet(img_dim, CHANNEL, n_class):\n",
    "    input_tensor = Input(shape=(224, 224, CHANNEL))\n",
    "    base_model = ResNet50(weights=None, include_top=False, input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/resnet50weightsfile/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(2048)(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    #x.add(LeakyReLU(alpha=0.1))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    #x.add(LeakyReLU(alpha=0.1))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output_layer = Dense(n_class, activation='softmax', name=\"Output_Layer\")(x)\n",
    "    model_resnet = Model(input_tensor, output_layer)\n",
    "\n",
    "    return model_resnet\n",
    "\n",
    "\n",
    "model_resnet = create_resnet(IMG_DIM, CHANNEL_SIZE, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Layers \n",
    "# for i, lay in enumerate(model_resnet.layers):\n",
    "#     print(i,lay.name)\n",
    "# Training All Layers\n",
    "\n",
    "for layers in model_resnet.layers:\n",
    "    layers.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True) # Adam(lr=lr, decay=0.01) \n",
    "model_resnet.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_resnet.fit_generator(generator=train_generator,\n",
    "                                     steps_per_epoch=NUB_TRAIN_STEPS,\n",
    "                                     validation_data=valid_generator,\n",
    "                                     validation_steps=NUB_VALID_STEPS,\n",
    "                                     epochs=15, \n",
    "                                     callbacks=[reduce_lr],\n",
    "                                     verbose=2)\n",
    "model_resnet.save('leakyresnet2702.h5')\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(accu, label=\"Accuracy\")\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Acc', 'val_acc'])\n",
    "plt.plot(np.argmax(history.history[\"val_acc\"]), np.max(history.history[\"val_acc\"]), marker=\"x\", color=\"r\",\n",
    "         label=\"best model\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n",
    "         label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a>\n",
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "(eval_loss, eval_accuracy) = tqdm(\n",
    "    model_resnet.evaluate_generator(generator=valid_generator, steps=NUB_VALID_STEPS, pickle_safe=False))\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2, horizontal_flip=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n",
    "                                                  directory=\"../input/aptos2019-blindness-detection/test_images/\",\n",
    "                                                  x_col=\"id_code\",\n",
    "                                                  target_size=(IMG_DIM, IMG_DIM),\n",
    "                                                  batch_size=1,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=None,\n",
    "                                                  seed=SEED)\n",
    "# del df_test\n",
    "print(df_test.shape[0])\n",
    "# del train_datagen\n",
    "# del traabsin_generator\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kapkaha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a>\n",
    "# Test-Time Augmentation\n",
    "In the below section, we are doning TTA imporving the prediction accuracy. It will transform image and predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_steps = 5\n",
    "preds_tta = []\n",
    "for i in tqdm(range(tta_steps)):\n",
    "    test_generator.reset()\n",
    "    preds = model_resnet.predict_generator(generator=test_generator, steps=ceil(df_test.shape[0]))\n",
    "    #     print('Before ', preds.shape)\n",
    "    preds_tta.append(preds)\n",
    "#     print(i,  len(preds_tta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = np.mean(preds_tta, axis=0)\n",
    "predicted_class_indices = np.argmax(final_pred, axis=1)\n",
    "len(predicted_class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator.filenames.apply(lambda x: x[-4])\n",
    "results = pd.DataFrame({\"id_code\": test_generator.filenames, \"diagnosis\": predicted_class_indices})\n",
    "results.id_code = results.id_code.apply(lambda x: x[:-4])  # results.head()\n",
    "results.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <a id=\"14\"></a>\n",
    " # Visualization Test Result\n",
    "- this section will visualize the predicted classes of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['diagnosis'].value_counts().plot(kind='bar')\n",
    "plt.title('Test Samples Per Class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1\n",
    "1. https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "1. https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "1. https://jkjung-avt.github.io/keras-image-cropping/\n",
    "1. https://www.kaggle.com/aleksandradeis/aptos2019-blindness-detection-eda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
